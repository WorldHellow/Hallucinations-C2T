{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "od1_g6SOraWM"
      },
      "outputs": [],
      "source": [
        "!pip3 install torch\n",
        "!pip3 install torchvision\n",
        "!pip3 install sentencepiece\n",
        "!pip3 install transformers\n",
        "!pip3 install datasets\n",
        "!pip install rouge-score\n",
        "!pip install sacrebleu\n",
        "!pip install git+https://github.com/google-research/bleurt.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aPJtavPFr3YF"
      },
      "outputs": [],
      "source": [
        "import datetime\n",
        "import os\n",
        "import time\n",
        "import sys\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import nltk\n",
        "import numpy as np\n",
        "import json\n",
        "\n",
        "import torch\n",
        "torch.manual_seed(49)\n",
        "from datasets import load_metric, load_dataset \n",
        "from transformers import AutoTokenizer,  AutoModelForSeq2SeqLM\n",
        "\n",
        "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
        "import statistics\n",
        "\n",
        "\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_checkpoint = ''\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "model =   AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint).to(device)\n"
      ],
      "metadata": {
        "id": "dDmXr2kUaoS-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pd.read_csv('data/c2t-big/test_c2t_big.csv', sep='\\t')\n",
        "test"
      ],
      "metadata": {
        "id": "z85hLi_O_MEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = list(test['Data'])\n",
        "test_summary = list(test['Summaries'])"
      ],
      "metadata": {
        "id": "GKv-1ikYO8Q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLNiXHJukeom"
      },
      "source": [
        "## Beam Search"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVbnE8ApEZa1"
      },
      "outputs": [],
      "source": [
        "hypo_summary = list()\n",
        "counter = 0\n",
        "for text in test_data:\n",
        "    print(counter)\n",
        "    tokens = tokenizer.encode('C2T: ' + text,  truncation=True, padding='max_length', return_tensors='pt').to('cuda')\n",
        "    generated = model.generate(tokens, num_beams=4, max_length = 256)\n",
        "    tgt_text = tokenizer.decode(generated[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
        "    summary = str(tgt_text).strip('[]\"\"')\n",
        "    print(summary)\n",
        "    hypo_summary.append(summary.replace('\\n',''))\n",
        "    counter = counter + 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hypo_file = open('hypothesis.txt', 'w')\n",
        "for i in hypo_summary_1:\n",
        "    hypo_file.write(i.replace('\\n','') + '\\n')\n",
        "hypo_file.close()"
      ],
      "metadata": {
        "id": "HKMfTAp8wVEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ROUGE and BLEU"
      ],
      "metadata": {
        "id": "KFu0xH-G3cXF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ozv8ioINkSa"
      },
      "outputs": [],
      "source": [
        "metric = load_metric('rouge')\n",
        "ref = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in test_summary]\n",
        "beam_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in hypo_summary]\n",
        "result = metric.compute(predictions=beam_preds, references=ref, use_stemmer=True)\n",
        "beam_rouge = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
        "beam_rouge"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric('sacrebleu')\n",
        "\n",
        "def postprocess_text(preds, labels):\n",
        "    preds = [pred.strip() for pred in preds]\n",
        "    labels = [[label.strip()] for label in labels]\n",
        "\n",
        "    return preds, labels\n",
        "\n",
        "def compute_metrics(preds,ref):\n",
        "\n",
        "    # Some simple post-processing\n",
        "    decoded_preds, decoded_labels = postprocess_text(preds, ref)\n",
        "\n",
        "    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
        "    r = result['score']\n",
        "    return r"
      ],
      "metadata": {
        "id": "n2qN0Okg9SQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = compute_metrics(hypo_summary,test_summary)\n",
        "print(r)"
      ],
      "metadata": {
        "id": "vt8C8ojGvdnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## BLEURT score"
      ],
      "metadata": {
        "id": "GhhmHIlQ87dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = load_metric('bleurt',module_type=\"metric\", checkpoint=\"bleurt-base-128\")"
      ],
      "metadata": {
        "id": "pI_pQtdc86kY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleurt = metric.compute(predictions=hypo_summary, references=test_summary)"
      ],
      "metadata": {
        "id": "JOLFZKas-0fv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(list(bleurt['scores'])))"
      ],
      "metadata": {
        "id": "98oghBDw_Z4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT-2 Perplexity"
      ],
      "metadata": {
        "id": "Qa1tgtq9DJqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import GPT2LMHeadModel, GPT2TokenizerFast\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "vxPj7qQGDIqS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\"\n",
        "model_id = \"gpt2-medium\"\n",
        "model = GPT2LMHeadModel.from_pretrained(model_id).to(device)\n",
        "tokenizer = GPT2TokenizerFast.from_pretrained(model_id)"
      ],
      "metadata": {
        "id": "fczu40FLDU3T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encodings = tokenizer(\"\\n\\n\".join(hypo_summary), return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "jU18dnd7DV8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_length = model.config.n_positions\n",
        "stride = 512\n",
        "\n",
        "nlls = []\n",
        "for i in tqdm(range(0, encodings.input_ids.size(1), stride)):\n",
        "    begin_loc = max(i + stride - max_length, 0)\n",
        "    end_loc = min(i + stride, encodings.input_ids.size(1))\n",
        "    trg_len = end_loc - i  # may be different from stride on last loop\n",
        "    input_ids = encodings.input_ids[:, begin_loc:end_loc].to(device)\n",
        "    target_ids = input_ids.clone()\n",
        "    target_ids[:, :-trg_len] = -100\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, labels=target_ids)\n",
        "        neg_log_likelihood = outputs[0] * trg_len\n",
        "\n",
        "    nlls.append(neg_log_likelihood)\n",
        "\n",
        "ppl = torch.exp(torch.stack(nlls).sum() / end_loc)"
      ],
      "metadata": {
        "id": "5EH47GpfDbNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ppl"
      ],
      "metadata": {
        "id": "4XE6FToNDbyN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgtpotC3d2JL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NUBIA"
      ],
      "metadata": {
        "id": "V53hPoPMnyJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/wl-research/nubia.git\n",
        "import os\n",
        "os.chdir('nubia')\n",
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "Bcd8_4IuN7ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "rcCMtF0EnwFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nubia_score import Nubia\n",
        "import statistics\n",
        "metric = Nubia()"
      ],
      "metadata": {
        "id": "y9POSs8-OGqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "beam_nubia_score = list()\n",
        "beam_logical_agreement = list()\n",
        "beam_semantic_relation = list()\n",
        "beam_irrelevancy = list() \n",
        "beam_contradiction = list()"
      ],
      "metadata": {
        "id": "HwWesPI8dIA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i, j in zip(hypo_summary_1, test_summary):\n",
        "  x = metric.score(i,j, get_features=True)\n",
        "  beam_nubia_score.append(x['nubia_score'])\n",
        "  count += 1\n",
        "  beam_logical_agreement.append(x['features']['logical_agreement'])\n",
        "  beam_semantic_relation.append(x['features']['semantic_relation'])\n",
        "  beam_irrelevancy.append(x['features']['irrelevancy'])\n",
        "  beam_contradiction.append(x['features']['contradiction'])\n",
        "  beam_grammar_ref.append(x['features']['grammar_ref'])\n",
        "  beam_grammar_hyp.append(x['features']['grammar_hyp'])\n",
        "  print(count)"
      ],
      "metadata": {
        "id": "sNXcdIcueAFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(statistics.mean(beam_nubia_score))\n",
        "print(statistics.mean(beam_logical_agreement))\n",
        "print(statistics.mean(beam_semantic_relation))\n",
        "print(statistics.mean(beam_irrelevancy))\n",
        "print(statistics.mean(beam_contradiction))"
      ],
      "metadata": {
        "id": "okDQSqaGiV4z"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "ZIGHv-bdkHaH",
        "30YgtX3Jj9sP",
        "XQCx3vJCj5CD",
        "_skDkpWDjhMk",
        "GhhmHIlQ87dk",
        "V53hPoPMnyJr",
        "cjec_ctghh5C",
        "hsEJi067hh5C"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
